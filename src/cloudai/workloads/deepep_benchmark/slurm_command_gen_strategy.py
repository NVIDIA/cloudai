# SPDX-FileCopyrightText: NVIDIA CORPORATION & AFFILIATES
# Copyright (c) 2024-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from pathlib import Path
from typing import List, cast

from cloudai.systems.slurm import SlurmCommandGenStrategy

from .deepep_benchmark import DeepEPBenchmarkCmdArgs, DeepEPBenchmarkTestDefinition


class DeepEPBenchmarkSlurmCommandGenStrategy(SlurmCommandGenStrategy):
    """Command generation strategy for DeepEP benchmark on Slurm systems."""

    def _append_head_node_detection(self, batch_script_content: List[str]) -> None:
        """
        Append bash commands to detect head node IP for torchrun.

        Args:
            batch_script_content: The list of script lines to append to.
        """
        batch_script_content.extend(
            [
                "",
                "nodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )",
                "nodes_array=($nodes)",
                "head_node=${nodes_array[0]}",
                'head_node_ip=$(srun --nodes=1 --ntasks=1 -w "$head_node" hostname --ip-address)',
                "",
                "echo Nodes: $SLURM_JOB_NODELIST",
                "echo Num Nodes: ${#nodes[@]}",
                "echo Head Node IP: $head_node_ip",
                "",
            ]
        )

    def _append_sbatch_directives(self, batch_script_content: List[str]) -> None:
        """
        Append SBATCH directives and head node detection setup for DeepEP.

        Args:
            batch_script_content: The list of script lines to append to.
        """
        super()._append_sbatch_directives(batch_script_content)
        self._append_head_node_detection(batch_script_content)

    def _container_mounts(self) -> List[str]:
        """Return container mounts specific to DeepEP benchmark."""
        tdef: DeepEPBenchmarkTestDefinition = cast(DeepEPBenchmarkTestDefinition, self.test_run.test)
        cmd_args: DeepEPBenchmarkCmdArgs = tdef.cmd_args

        config_file_path = self.test_run.output_path / "config.yaml"
        self._generate_config_yaml(config_file_path, cmd_args)

        mounts = [
            f"{config_file_path.parent.absolute()}:{config_file_path.parent.absolute()}",
            f"{self.test_run.output_path.absolute()}:{cmd_args.results_dir}",
        ]

        return mounts

    def image_path(self) -> str | None:
        """Return the Docker image path for DeepEP benchmark."""
        tdef: DeepEPBenchmarkTestDefinition = cast(DeepEPBenchmarkTestDefinition, self.test_run.test)
        return str(tdef.docker_image.installed_path)

    def generate_test_command(self) -> List[str]:
        """Generate the test command for DeepEP benchmark."""
        tdef: DeepEPBenchmarkTestDefinition = cast(DeepEPBenchmarkTestDefinition, self.test_run.test)
        cmd_args: DeepEPBenchmarkCmdArgs = tdef.cmd_args

        if cmd_args.mode == "standard":
            benchmark_script = "/workspace/dp-benchmark/benchmark/benchmark.py"
        else:
            benchmark_script = "/workspace/dp-benchmark/benchmark/benchmark_ll.py"

        _, nodes = self.system.get_nodes_by_spec(self.test_run.nnodes, self.test_run.nodes)
        num_nodes = len(nodes) if nodes else self.test_run.nnodes

        config_file_path = self.test_run.output_path / "config.yaml"
        command_parts = [
            "torchrun",
            f"--nnodes={num_nodes}",
            "--nproc_per_node=1",
            "--rdzv_id=$RANDOM",
            "--rdzv_backend=c10d",
            "--rdzv_endpoint=$head_node_ip:29500",
            benchmark_script,
            str(config_file_path.absolute()),
        ]

        return command_parts

    def _generate_config_yaml(self, config_path: Path, cmd_args: DeepEPBenchmarkCmdArgs) -> None:
        """
        Generate YAML configuration file for DeepEP benchmark.

        Args:
            config_path: Path where to write the config file.
            cmd_args: Command arguments for the benchmark.
        """
        tdef: DeepEPBenchmarkTestDefinition = cast(DeepEPBenchmarkTestDefinition, self.test_run.test)

        config_lines = [
            "# DeepEP Benchmark Configuration",
            "# Generated by CloudAI",
            "",
        ]

        for key, value in tdef.cmd_args_dict.items():
            if isinstance(value, bool):
                config_lines.append(f"{key}: {str(value).lower()}")
            elif isinstance(value, str):
                config_lines.append(f'{key}: "{value}"')
            else:
                config_lines.append(f"{key}: {value}")

        config_path.parent.mkdir(parents=True, exist_ok=True)

        with open(config_path, "w") as f:
            f.write("\n".join(config_lines))

    def gen_srun_success_check(self) -> str:
        """Check if DeepEP benchmark completed successfully."""
        output_file = self.test_run.output_path / "stdout.txt"
        return f'grep -q "global_bw\\|deepep_time" {output_file} && echo 1 || echo 0'
