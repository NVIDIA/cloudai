#!/bin/bash
# generated by CloudAI@__CLOUDAI_VERSION__
#SBATCH --job-name=__JOB_NAME__
#SBATCH --output=__OUTPUT_DIR__/output/stdout.txt
#SBATCH --error=__OUTPUT_DIR__/output/stderr.txt
#SBATCH --partition=main
#SBATCH -N 2
#SBATCH --gpus-per-node=8
#SBATCH --gres=gpu:8

export SLURM_JOB_MASTER_NODE=$(scontrol show hostname $SLURM_JOB_NODELIST | head -n 1)

srun --export=ALL --mpi=pmix -N2 --container-image=nvcr.io/nvidia/ai-dynamo:24.09 --container-mounts=__OUTPUT_DIR__/output:/cloudai_run_results,__OUTPUT_DIR__/install:/cloudai_install,__OUTPUT_DIR__/output,__INSTALL_DIR__:__INSTALL_DIR__,__OUTPUT_DIR__/output/hf_home:/root/.cache/huggingface,__CLOUDAI_DIR__/src/cloudai/workloads/ai_dynamo/ai_dynamo.sh:__CLOUDAI_DIR__/src/cloudai/workloads/ai_dynamo/ai_dynamo.sh --output=__OUTPUT_DIR__/output/mapping-stdout.txt --error=__OUTPUT_DIR__/output/mapping-stderr.txt bash -c "echo \$(date): \$(hostname):node \${SLURM_NODEID}:rank \${SLURM_PROCID}."

srun --export=ALL --mpi=pmix -N2 --container-image=nvcr.io/nvidia/ai-dynamo:24.09 --container-mounts=__OUTPUT_DIR__/output:/cloudai_run_results,__OUTPUT_DIR__/install:/cloudai_install,__OUTPUT_DIR__/output,__INSTALL_DIR__:__INSTALL_DIR__,__OUTPUT_DIR__/output/hf_home:/root/.cache/huggingface,__CLOUDAI_DIR__/src/cloudai/workloads/ai_dynamo/ai_dynamo.sh:__CLOUDAI_DIR__/src/cloudai/workloads/ai_dynamo/ai_dynamo.sh --ntasks=2 --ntasks-per-node=1 --output=__OUTPUT_DIR__/output/metadata/node-%N.toml --error=__OUTPUT_DIR__/output/metadata/nodes.err bash /cloudai_install/slurm-metadata.sh

num_retries=${DYNAMO_NUM_RETRY_ON_FAILURE:-0}
for try in $(seq 0 $num_retries); do
  echo "Try $try of $num_retries"
  rm -f __OUTPUT_DIR__/output/fatal_error.marker 2>/dev/null || true
  srun \
  --export=ALL \
  --mpi=pmix \
  -N2 \
  --container-image=nvcr.io/nvidia/ai-dynamo:24.09 \
  --container-mounts=__OUTPUT_DIR__/output:/cloudai_run_results,__OUTPUT_DIR__/install:/cloudai_install,__OUTPUT_DIR__/output,__INSTALL_DIR__:__INSTALL_DIR__,__OUTPUT_DIR__/output/hf_home:/root/.cache/huggingface,__CLOUDAI_DIR__/src/cloudai/workloads/ai_dynamo/ai_dynamo.sh:__CLOUDAI_DIR__/src/cloudai/workloads/ai_dynamo/ai_dynamo.sh \
  --nodes=2 \
  --ntasks=2 \
  --ntasks-per-node=1 \
  --export=ALL,DYNAMO_FATAL_ERROR_FILE=fatal_error.marker \
  --output=__OUTPUT_DIR__/output/node-%n-stdout.txt \
  --error=__OUTPUT_DIR__/output/node-%n-stderr.txt \
  bash \
  __CLOUDAI_DIR__/src/cloudai/workloads/ai_dynamo/ai_dynamo.sh \
  --huggingface-home /root/.cache/huggingface \
  --results-dir /cloudai_run_results \
  --dynamo-backend "vllm" \
  --prefill-num-nodes "1" \
  --prefill-ServiceArgs "{'workers': 1, 'resources': {'gpu': '8'}}" \
  --decode-num-nodes "1" \
  --decode-ServiceArgs "{'workers': 1, 'resources': {'gpu': '8'}}" \
  --genai-perf-streaming "True" \
  --genai-perf-extra-inputs "{"temperature": 0.7, "max_tokens": 128}" \
  --genai-perf-output-tokens-mean "128" \
  --genai-perf-random-seed "42" \
  --genai-perf-request-count "100" \
  --genai-perf-synthetic-input-tokens-mean "550" \
  --genai-perf-warmup-request-count "10"
  if [ $try -eq $num_retries ] || [ ! -f __OUTPUT_DIR__/output/fatal_error.marker ]; then
    break
  fi
  echo "Fatal error detected. Archiving logs then retrying..."
  mkdir -p __OUTPUT_DIR__/output/error.$try
  mv __OUTPUT_DIR__/output/*.log __OUTPUT_DIR__/output/error.$try/ 2>/dev/null || true
  mv __OUTPUT_DIR__/output/node-*-stdout.txt __OUTPUT_DIR__/output/error.$try/ 2>/dev/null || true
  mv __OUTPUT_DIR__/output/node-*-stderr.txt __OUTPUT_DIR__/output/error.$try/ 2>/dev/null || true
  mv __OUTPUT_DIR__/output/fatal_error.marker __OUTPUT_DIR__/output/error.$try/ 2>/dev/null || true
  sleep ${DYNAMO_RETRY_BACKOFF_SEC:-10}
done